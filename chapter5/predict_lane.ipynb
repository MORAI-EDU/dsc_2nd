{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install segmentation-models-pytorch\n",
    "!pip install albumentations\n",
    "!pip install --upgrade efficientnet-pytorch\n",
    "!pip install openpyxl\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install -U albumentations[imgaug]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                                      # 파이썬 수치 계산을 위한 라이브러리\n",
    "import pandas as pd                                                     # 파이썬 데이터 분석을 위한 라이브러리\n",
    "import os                                                               # 폴더 검색 등 os에 관련된 명령어 사용을 위한 라이브러리                                                       \n",
    "import matplotlib.pyplot as plt                                         # 데이터 시각화를 위한 라이브러리\n",
    "import cv2                                                              # OpenCV 라브러리 사용을 위한 라이브러리\n",
    "import re                                                               # 정규 표현식을 사용해 문자열 처리를 위한 라이브러리\n",
    "\n",
    "import torch                                                            # 딥러닝 프레임워크인 pytorch 라이브러리\n",
    "from torch import LongTensor                                            # pytorch의 Tensor class중 하나인 LongTensor를 불러옴\n",
    "from torch.utils.data import DataLoader, Dataset                        # 데이터를 불러오는 class인 DataLoader와 데이터셋 구성을 위한 Dataset class를 불러옴 \n",
    "\n",
    "\n",
    "\n",
    "import segmentation_models_pytorch as SM                                # 다양한 segmentation model을 불러오기 위한 라이브러리\n",
    "from segmentation_models_pytorch.utils.losses import DiceLoss           # segmentation 모델에서 사용하는 손실 함수인 DiceLoss를 불러옴\n",
    "from segmentation_models_pytorch.utils.metrics import Accuracy          # segmentation 모델의 평가 지표 중 하나인 Accuracy를 불러옴\n",
    "from segmentation_models_pytorch.utils import base                      # segmentation_models_pytorch 라이브러리의 기분 유틸리티 함수 및 클래스를 불러옴\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\"\n",
    "print(os.listdir(data_dir))   # 현재 디렉토리의 파일 출력\n",
    "\n",
    "train_set = os.path.join(data_dir,'tr')\n",
    "tr_imgs = os.listdir(train_set)\n",
    "train_label = os.path.join(data_dir,\"tr_lb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 확인해보기\n",
    "img = plt.imread(os.path.join(data_dir,\"tr\", tr_imgs[0]))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#라벨링 이미지 확인해보기\n",
    "label_img = os.listdir(train_label)\n",
    "label_img = plt.imread(os.path.join(data_dir,\"tr_lb\", label_img[0]))\n",
    "plt.imshow(label_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'data'\n",
    "train_x = os.path.join(root_dir,'tr')\n",
    "train_y = os.path.join(root_dir,'tr_lb')\n",
    "\n",
    "val_x = os.path.join(root_dir,'val')\n",
    "val_y = os.path.join(root_dir,'val_lb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 plot 함수\n",
    "def plot_img(**img):\n",
    "    img_len = len(img)\n",
    "    \n",
    "    plt.figure(figsize=(16, 5))\n",
    "    \n",
    "    for i, (j, k) in enumerate(img.items()):\n",
    "        plt.subplot(1, img_len, i + 1)\n",
    "        \n",
    "        \n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        \n",
    "        plt.title(' '.join(j.split('_')).title())\n",
    "        plt.imshow(k)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaneData(Dataset):                                                                                # pytorch의 Dataset을 상속받는 LaneData라는 class 선언\n",
    "    y_class = ['bg','left','right']                                                                     # y값은 'bg', 'left', 'right'인 정답 label 선언\n",
    "    \n",
    "    def __init__(self, img_dir, msk_dir, augment=None,y_class=None,preproc=None):                       \n",
    "        self.img_dir = os.listdir(img_dir)                                                              # 이미지 디렉토리에서 이미지 파일 목록을 가져옴\n",
    "        self.img_path = [os.path.join(img_dir, img_idx) for img_idx in self.img_dir]                    # 이미지 파일 경로 리스트 생성\n",
    "        get_lb_name = lambda x: re.sub(\".png\", \"_label.png\", x)                                         # 마스크 파일 경로 생성을 위한 함수\n",
    "        \n",
    "        self.msk_path = [os.path.join(msk_dir, get_lb_name(img_idx)) for img_idx in self.img_dir]       # 데이터 augmentation 설정\n",
    "        \n",
    "        self.augment = augment                                                                          # 정답 레이블의 클래스 인덱스 설정\n",
    "\n",
    "    \n",
    "        self.class_v = [self.y_class.index(cls.lower()) for cls in y_class]                             # 데이터 전처리 설정\n",
    "        \n",
    "        self.preproc = preproc                                                                          # 데이터 전처리 설정\n",
    "                    \n",
    "    def __len__(self):                                                                                  \n",
    "        return len(self.img_dir)                                                                        # 데이터셋의 갯수 반환\n",
    "    \n",
    "    def __getitem__(self, idx):                                                                         # 데이터셋을 불러옴\n",
    "     \n",
    "        img = cv2.imread(self.img_path[idx])                                                            # 이미지를 불러옴\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)                                                      # 이미지를 COLOR이미지로 설정\n",
    "        msk = cv2.imread(self.msk_path[idx], 0)                                                         # 마스크 데이터를 불러옴\n",
    "        \n",
    "        if self.augment:                                                                                # augmentation이 설정되어 있을 시 해당 코드 실행\n",
    "            sample = self.augment(image=img, mask=msk)                                                  # sample이라는 변수에 이미지와 마스크 데이터를 augmentation 진행 \n",
    "            img, msk = sample['image'], sample['mask']                                                  # augmentation이 완료된 값을 img와 msk라는 변수에 저장\n",
    "    \n",
    "        if self.preproc:                                                                                # 데이터 전처리가 설정되어 있을 시 해당 코드 실행\n",
    "            sample = self.preproc(image=img, mask=msk)                                                  # img와 msk 데이터를 전처리 진행\n",
    "            img, msk = sample['image'], sample['mask']                                                  # 전처리 완료된 데이터를 img와 msk 변수에 각각 저장\n",
    "            \n",
    "        return img, LongTensor(msk)                                                                     # 이미지와 마스크 데이터를 Tensor 형태로 변환\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LaneData(train_x, train_y,y_class=LaneData.y_class)   # LaneData class를 이용해 train_x와 train_y를 활용한 dataset 생성                 \n",
    "\n",
    "img, msk = dataset[1]                                           # 이미지 plot 해보기위해 dataset의 두번째 인덱스 값을 img와 msk에 저장                                                                   \n",
    "plot_img(                                                       # img와 msk값을 각각 plot\n",
    "    image = img, \n",
    "    label = msk\n",
    ")                                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as AB\n",
    "\n",
    "def get_tr_aug():\n",
    "    tr_tf = [\n",
    "        AB.ShiftScaleRotate(scale_limit=0.1, rotate_limit=0., shift_limit=0.1, p=1, border_mode=0),     # 이미지의 크기와 위치를 무작위로 변환\n",
    "        AB.IAAAdditiveGaussianNoise(p=0.2),                                                             # 가우시안 노이즈 추가\n",
    "        AB.OneOf([\n",
    "            AB.CLAHE(p=1),                                                                              # 이미지의 대비를 개선\n",
    "            AB.RandomBrightness(p=1),                                                                   # 이미지의 밝기를 무작위로 변화\n",
    "            AB.RandomGamma(p=1),                                                                        # 이미지의 감마값을 무작위로 변화\n",
    "        ], p=0.6),\n",
    "        AB.OneOf([\n",
    "            AB.IAASharpen(p=1),                                                                         # 이미지를 날카롭게 만듦\n",
    "            AB.Blur(blur_limit=3, p=1),                                                                 # 이미지를 블러처리\n",
    "            AB.MotionBlur(blur_limit=3, p=1),                                                           # 이미지에 모션 블러 효과 추가\n",
    "        ], p=0.6),\n",
    "        AB.OneOf([\n",
    "            AB.RandomContrast(p=1),                                                                     # 이미지의 대비를 무작위로 변화\n",
    "            AB.HueSaturationValue(p=1),                                                                 # 이미지의 색상과 채도를 무작위로 변화\n",
    "        ], p=0.6),\n",
    "    ]\n",
    "    return AB.Compose(tr_tf)\n",
    "\n",
    "\n",
    "def get_val_aug():\n",
    "    return None\n",
    "\n",
    "\n",
    "def _ToTensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "\n",
    "def get_preprocess(preprocess_fn):   \n",
    "    _tf = [\n",
    "        AB.Lambda(image=preprocess_fn),                                                                 # 이미지에 전처리 함수 적용\n",
    "        AB.Lambda(image=_ToTensor),                                                                     # 이미지를 텐서 형태로 변환\n",
    "    ]\n",
    "    return AB.Compose(_tf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_dataset = LaneData(                    \n",
    "    train_x, \n",
    "    train_y, \n",
    "    augment=get_tr_aug(), \n",
    "    y_class=LaneData.y_class\n",
    ")\n",
    "\n",
    "for i in range(3):\n",
    "    img, msk = aug_dataset[i]\n",
    "    plot_img(image=img, label=msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_set = 'multi_dice_loss'                                                                # 사용할 loss 함수 설정\n",
    "\n",
    "encoder = 'efficientnet-b0'                                                                 # 사용할 encoder 모델 설정\n",
    "encoder_w = 'imagenet'                                                                      # encoder 모델의 가중치 설정\n",
    "ACTIVATION = 'softmax2d'                                                                    # 활성화 함수 설정\n",
    "DEVICE = 'cuda'                                                                             # 사용할 디바이스 설정\n",
    "\n",
    "# pretrained encoder를 사용하여 segmentation model 생성\n",
    "model = SM.FPN(\n",
    "    encoder_name=encoder, \n",
    "    encoder_weights=encoder_w, \n",
    "    classes=len(LaneData.y_class), \n",
    "    activation=ACTIVATION,\n",
    "    #encoder_depth = 4\n",
    ")\n",
    "\n",
    "preprocessing_fn = SM.encoders.get_preprocessing_fn(encoder, encoder_w)                     # 전처리 함수 설정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LaneData(                                   # augmentation과 전처리가 들어간 train_dataset 생성\n",
    "    train_x, \n",
    "    train_y, \n",
    "    augment=get_tr_aug(), \n",
    "    preproc=get_preprocess(preprocessing_fn),\n",
    "    y_class=LaneData.y_class,\n",
    ")\n",
    "valid_dataset = LaneData(                                   # augmentation과 전처리가 들어간 valid_dataset 생성\n",
    "    val_x, \n",
    "    val_y, \n",
    "    augment=get_val_aug(), \n",
    "    preproc=get_preprocess(preprocessing_fn),\n",
    "    y_class=LaneData.y_class,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tr = 4                                                                                # 학습 데이터 배치 크기 설정\n",
    "batch_val = 4                                                                               # 검증 데이터 배치 크기 설정\n",
    "\n",
    "tr_loader = DataLoader(train_dataset, batch_size=batch_tr, shuffle=True)                    # 학습 데이터 로더 생성\n",
    "val_loader = DataLoader(valid_dataset, batch_size=batch_val, shuffle=False)                 # 검증 데이터 로더 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models_pytorch.utils.losses import DiceLoss                                   # Dice Loss를 계산하기 위한 모듈\n",
    "from segmentation_models_pytorch.utils.metrics import Accuracy                                  # 정확도 측정을 위한 모듈\n",
    "from segmentation_models_pytorch.utils import base                                              # Segmentation 모델에 사용되는 유틸리티 모듈\n",
    "\n",
    "label_left = LaneData.y_class.index('left')                                                     # 'left' 클래스의 레이블 인덱스 설정\n",
    "label_right = LaneData.y_class.index('right')                                                   # 'right' 클래스의 레이블 인덱스 설정\n",
    "\n",
    "class MultiDiceLoss(base.Loss):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.BinaryDiceLossLeft = DiceLoss()                                                    # 'left' 클래스에 대한 Dice Loss를 계산하기 위한 객체 생성\n",
    "        self.BinaryDiceLossRight = DiceLoss()                                                   # 'right' 클래스에 대한 Dice Loss를 계산하기 위한 객체 생성\n",
    "        \n",
    "    def forward(self, y_pr, y_gt):\n",
    "        #print(\"shape y_pr:\", y_pr.shape)\n",
    "        #print(\"shape y_gt:\", y_gt.shape)\n",
    "        # ypr.shape=bs,3,512,1024, ygt.shape=bs,512,1024\n",
    "        left_gt = (y_gt == label_left)                                                          # 'left' 클래스에 해당하는 ground truth 생성\n",
    "        right_gt = (y_gt == label_right)                                                        # 'right' 클래스에 해당하는 ground truth 생성\n",
    "        loss_left = self.BinaryDiceLossLeft.forward(y_pr[:, label_left, :, :], left_gt)         # 'left' 클래스에 대한 Dice Loss 계산\n",
    "        loss_right = self.BinaryDiceLossRight.forward(y_pr[:, label_right, :, :], right_gt)     # 'right' 클래스에 대한 Dice Loss 계산\n",
    "        return (loss_left + loss_right) * 0.5                                                   # 두 클래스의 Loss의 평균 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []                                                        # 사용할 메트릭스 리스트\n",
    "loss = MultiDiceLoss()                                              # 정의한 MultiDiceLoss 객체를 loss로 설정\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-4)    # Adam 옵티마이저를 생성하고 모델의 파라미터와 학습률을 설정하여 초기화\n",
    "\n",
    "train_epoch = SM.utils.train.TrainEpoch(\n",
    "    model,                                                          # 학습할 모델\n",
    "    loss=loss,                                                      # 사용할 손실 함수 (MultiDiceLoss)\n",
    "    metrics=metrics,                                                # 사용할 메트릭스 리스트\n",
    "    optimizer=optimizer,                                            # 사용할 옵티마이저 (Adam)\n",
    "    device=DEVICE,                                                  # 사용할 디바이스 (cuda)\n",
    "    verbose=True,                                                   # 학습 과정에서 로그를 출력할지 여부\n",
    ")\n",
    "\n",
    "valid_epoch = SM.utils.train.ValidEpoch(\n",
    "    model,                                                          # 평가할 모델\n",
    "    loss=loss,                                                      # 사용할 손실 함수 (MultiDiceLoss)\n",
    "    metrics=metrics,                                                # 사용할 메트릭스 리스트\n",
    "    device=DEVICE,                                                  # 사용할 디바이스 (cuda)\n",
    "    verbose=True,                                                   # 평가 과정에서 로그를 출력할지 여부\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = 1e10                                                    # 최적의 손실값을 저장할 변수 초기화\n",
    "\n",
    "for i in range(0, 5):                                               # 5번의 에포크 동안 반복\n",
    "\n",
    "    print('\\nEpoch: {}'.format(i))                                  # 현재 에포크 번호 출력\n",
    "    train_logs = train_epoch.run(tr_loader)                         # 학습 과정 실행 및 로그 저장\n",
    "    valid_logs = valid_epoch.run(val_loader)                        # 평가 과정 실행 및 로그 저장\n",
    "\n",
    "    if best_loss > valid_logs[loss_set]:                            # 현재 손실값이 최적의 손실값보다 작은 경우\n",
    "        best_loss = valid_logs[loss_set]                            # 최적의 손실값 업데이트\n",
    "        torch.save(model, './best_model_{}.pth'.format(loss_set))   # 모델 저장\n",
    "        print('Model saved!')\n",
    "        \n",
    "    if i == 3:                                                      # 3번째 에포크에서\n",
    "        optimizer.param_groups[0]['lr'] = 1e-5                      # 디코더의 학습률을 1e-5로 감소\n",
    "        print('Decrease decoder learning rate to 1e-5!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = torch.load('./best_model_multi_dice_loss.pth')         # 저장된 최적 모델을 불러옵니다.\n",
    "\n",
    "test_best_model = True                                              # 최적 모델을 테스트할지 여부를 설정합니다.\n",
    "if test_best_model:\n",
    "    test_dataset = LaneData(                                        # 테스트 데이터셋을 생성합니다.\n",
    "        val_x, \n",
    "        val_y, \n",
    "        augment=get_val_aug(), \n",
    "        preproc=get_preprocess(preprocessing_fn),\n",
    "        y_class=LaneData.y_class,\n",
    "    )\n",
    "\n",
    "    test_dataloader = DataLoader(test_dataset)                      # 테스트 데이터로더를 생성합니다.\n",
    "\n",
    "    test_epoch = SM.utils.train.ValidEpoch(                         # 테스트를 위한 ValidEpoch 객체를 생성합니다.\n",
    "        model=best_model,\n",
    "        loss=loss,\n",
    "        metrics=metrics,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "\n",
    "    logs = test_epoch.run(test_dataloader)                          # 테스트 데이터셋에 대한 평가를 수행합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_plot = LaneData(\n",
    "    val_x, val_y, \n",
    "    y_class=LaneData.y_class,\n",
    "    preproc=get_preprocess(preprocessing_fn)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_plot = LaneData(\n",
    "    val_x, val_y,                                   # 검증 데이터셋 (이미지와 마스크) 생성\n",
    "    y_class=LaneData.y_class,                       # 클래스 레이블 설정\n",
    "    preproc=get_preprocess(preprocessing_fn)        # 전처리 함수 적용\n",
    ")\n",
    "\n",
    "for i in range(3):\n",
    "    n = np.random.choice(len(test_dataset_plot))\n",
    "\n",
    "    # 시각화할 이미지와 ground truth 마스크 가져오기\n",
    "    image_vis = test_dataset_plot[n][0].astype('uint8')\n",
    "    image, gt_mask = test_dataset_plot[n]\n",
    "    \n",
    "    print(np.shape(image))\n",
    "\n",
    "    # 입력 이미지를 텐서로 변환하고 모델로부터 예측된 마스크 가져오기\n",
    "    x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n",
    "    pr_mask_left = best_model.predict(x_tensor)[0, 1, :, :]\n",
    "    pr_mask_left = pr_mask_left.cpu().numpy()\n",
    "\n",
    "    pr_mask_right = best_model.predict(x_tensor)[0, 2, :, :]\n",
    "    pr_mask_right = pr_mask_right.cpu().numpy()\n",
    "\n",
    "    # 이미지와 예측된 마스크 시각화\n",
    "    plot_img(\n",
    "        image=image_vis,                        # 이미지\n",
    "        ground_truth_mask=gt_mask,              # GT값 마스크\n",
    "        predicted_mask_left=pr_mask_left,       # 왼쪽 예측 마스크\n",
    "        predicted_mask_right=pr_mask_right      # 오른쪽 예측 마스크\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cdb85f021449ee7cd66ccce4a0ba823d27c931af6689ebca0c867c00b03e16a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
